{
  "title": "Backpropagation Part 3",
  "description": "In this video, I discuss how \"gradient descent\" can be used to adjust the weights during back propagation in my \"toy\" JavaScript neural network library.",
  "videoId": "8H2ODPNxEgA",
  "nebulaSlug": "",
  "date": "2018-02-05",
  "languages": [],
  "topics": ["neural network", "backpropagation"],
  "canContribute": true,
  "timestamps": [
    {
      "time": "0:00",
      "title": "Introduction"
    },
    {
      "time": "",
      "title": ""
    },
    {
      "time": "",
      "title": ""
    },
    {
      "time": "",
      "title": ""
    },
    {
      "time": "",
      "title": ""
    }
  ],
  "credits": [
    {
      "title": "Editing",
      "name": "Mathieu Blanchette"
    },
    {
      "title": "Animations",
      "name": "Jason Heglund"
    }
  ]
}
